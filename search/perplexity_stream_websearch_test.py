import requests
import json
import time
import os

# API í‚¤ ì„¤ì • (ì‹¤ì œ ì‚¬ìš© ì‹œ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
pplx_api_key = os.getenv("PPLX_API_KEY")

def websearch_with_stream(query: str, stream: bool = True, max_results: int = 5):
    """
    Perplexity APIë¥¼ ì‚¬ìš©í•œ ì›¹ê²€ìƒ‰ - ìŠ¤íŠ¸ë¦¼ ëª¨ë“œ ì§€ì›
    
    Args:
        query: ê²€ìƒ‰í•  ì¿¼ë¦¬
        stream: ìŠ¤íŠ¸ë¦¼ ëª¨ë“œ ì‚¬ìš© ì—¬ë¶€
        max_results: ë°˜í™˜í•  ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 5)
    """
    url = "https://api.perplexity.ai/chat/completions"
    
    payload = {
        "model": "sonar",  # sonar ëŒ€ì‹  sonar-pro ì‚¬ìš©
        "messages": [
            {
                "content": f"""
You are WebSearchBot, an AI assistant specialized in performing natural-language web searches and returning structured results.  

When a user asks a question in natural language:
1. Treat the entire user input as a search query.
2. Perform a real-time web search (e.g., via an API or search engine).
3. Return EXACTLY {max_results} search results (no more, no less).
4. For each result, return a JSON object with these fields:
   - title: ë¬¸ì„œ ì œëª© (UTF-8 í…ìŠ¤íŠ¸, HTML íƒœê·¸ ì œê±°)
   - url: ë¬¸ì„œ URL
   - snippet: ê²€ìƒ‰ì–´ì™€ ì—°ê´€ëœ ìš”ì•½ë¬¸(ìµœì†Œ 200ì), ë¬¸ë§¥ ë’¤ "â€¦"ë¡œ íŠ¸ë ì¼€ì´íŠ¸
   - score: ê²€ìƒ‰ ê²°ê³¼ì˜ ìœ ì‚¬ë„ ì ìˆ˜(ì†Œìˆ˜ì  3ìë¦¬)
   - favicon: ë¬¸ì„œì˜ íŒŒë¹„ì½˜ URL
5. Return the overall answer as a JSON ë°°ì—´ë§Œ, ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ ì¶œë ¥í•˜ì„¸ìš”.
6. ì‘ë‹µì€ ë°˜ë“œì‹œ UTF-8 ì¸ì½”ë”©ìœ¼ë¡œ ì²˜ë¦¬í•˜ê³ , ëª¨ë“  ë¹„ASCII ë¬¸ìë¥¼ ê·¸ëŒ€ë¡œ ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤.
7. ê²°ê³¼ê°€ {max_results}ê°œ ë¯¸ë§Œì´ë©´ ë¹ˆ ê°ì²´ë¡œ ì±„ì›Œì„œ ì •í™•íˆ {max_results}ê°œë¥¼ ë°˜í™˜í•˜ì„¸ìš”.
8. ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ë¹ˆ ë°°ì—´ `[]`ì„ ë°˜í™˜í•˜ì„¸ìš”.

Example response (for max_results=3):
[
  {{
    "title": "ì²« ë²ˆì§¸ ê²€ìƒ‰ ê²°ê³¼ ì œëª©",
    "url": "https://example1.com/article",
    "snippet": "â€¦ì²« ë²ˆì§¸ ê²€ìƒ‰ ê²°ê³¼ì˜ ìš”ì•½ ë‚´ìš©ì…ë‹ˆë‹¤. ìµœì†Œ 200ì ì´ìƒì˜ ìƒì„¸í•œ ì„¤ëª…ì„ í¬í•¨í•©ë‹ˆë‹¤â€¦",
    "score": 0.952,
    "favicon": "https://example1.com/favicon.ico"
  }},
  {{
    "title": "ë‘ ë²ˆì§¸ ê²€ìƒ‰ ê²°ê³¼ ì œëª©",
    "url": "https://example2.com/article",
    "snippet": "â€¦ë‘ ë²ˆì§¸ ê²€ìƒ‰ ê²°ê³¼ì˜ ìš”ì•½ ë‚´ìš©ì…ë‹ˆë‹¤. ì—­ì‹œ ìƒì„¸í•œ ì„¤ëª…ì„ í¬í•¨í•©ë‹ˆë‹¤â€¦",
    "score": 0.887,
    "favicon": "https://example2.com/favicon.ico"
  }},
  {{
    "title": "ì„¸ ë²ˆì§¸ ê²€ìƒ‰ ê²°ê³¼ ì œëª©",
    "url": "https://example3.com/article",
    "snippet": "â€¦ì„¸ ë²ˆì§¸ ê²€ìƒ‰ ê²°ê³¼ì˜ ìš”ì•½ ë‚´ìš©ì…ë‹ˆë‹¤. ì •í™•íˆ {max_results}ê°œë¥¼ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤â€¦",
    "score": 0.823,
    "favicon": "https://example3.com/favicon.ico"
  }}
]
                """,
                "role": "system"
            },
            {
                "role": "user",
                "content": query
            }
        ],
        "search_domain_filter": ["-youtube.com", "-youtube.be"],
        "search_mode": "web",
        "reasoning_effort": "medium",
        "temperature": 0.5,
        "top_p": 0.2,
        "stream": stream,  # ìŠ¤íŠ¸ë¦¼ ì„¤ì •
        "web_search_options": {"search_context_size": "medium"},
    }
    
    headers = {
        "Authorization": f"Bearer {pplx_api_key}",
        "Content-Type": "application/json"
    }
    
    print(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
    print(f"ğŸ“¡ ìŠ¤íŠ¸ë¦¼ ëª¨ë“œ: {'ON' if stream else 'OFF'}")
    print(f"ğŸ“Š ìµœëŒ€ ê²°ê³¼ ìˆ˜: {max_results}ê°œ")
    print("-" * 60)
    
    if stream:
        return _handle_stream_response(url, payload, headers, max_results)
    else:
        return _handle_non_stream_response(url, payload, headers, max_results)


def _handle_stream_response(url, payload, headers, max_results):
    """ìŠ¤íŠ¸ë¦¼ ì‘ë‹µ ì²˜ë¦¬"""
    try:
        response = requests.post(url, json=payload, headers=headers, stream=True)
        
        if response.status_code != 200:
            print(f"âŒ API ì˜¤ë¥˜: {response.status_code}")
            print(f"ì˜¤ë¥˜ ë‚´ìš©: {response.text}")
            return None
        
        print("ğŸ“¡ ìŠ¤íŠ¸ë¦¼ ì‘ë‹µ ì‹œì‘...\n")
        
        full_content = ""
        chunk_count = 0
        start_time = time.time()
        first_chunk_time = None
        
        for line in response.iter_lines():
            if line:
                line_str = line.decode('utf-8')
                
                if line_str.startswith('data: '):
                    data_part = line_str[6:]
                    
                    if data_part.strip() == '[DONE]':
                        print("\n\nâœ… ìŠ¤íŠ¸ë¦¼ ì™„ë£Œ!")
                        break
                    
                    try:
                        chunk_data = json.loads(data_part)
                        chunk_count += 1
                        
                        if chunk_count == 1:
                            first_chunk_time = time.time() - start_time
                            print("ğŸš€ ì²« ë²ˆì§¸ ì²­í¬ ë„ì°©!\n")
                        
                        if 'choices' in chunk_data and len(chunk_data['choices']) > 0:
                            choice = chunk_data['choices'][0]
                            
                            if 'delta' in choice and 'content' in choice['delta']:
                                content = choice['delta']['content']
                                if content:
                                    print(content, end='', flush=True)
                                    full_content += content
                            
                            if choice.get('finish_reason'):
                                print(f"\n\nâœ… ì™„ë£Œ ì‚¬ìœ : {choice['finish_reason']}")
                                break
                        
                    except json.JSONDecodeError as e:
                        print(f"\nâŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
        
        total_time = time.time() - start_time
        
        print(f"\n\nğŸ“Š ìŠ¤íŠ¸ë¦¼ í†µê³„:")
        print(f"ì´ ì²­í¬ ìˆ˜: {chunk_count}")
        print(f"ì²« ì²­í¬ê¹Œì§€: {first_chunk_time:.2f}ì´ˆ" if first_chunk_time else "ì²« ì²­í¬ ì‹œê°„ ì¸¡ì • ì‹¤íŒ¨")
        print(f"ì „ì²´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ")
        print(f"ì‘ë‹µ ê¸¸ì´: {len(full_content)} ë¬¸ì")
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            parsed_result = json.loads(full_content)
            print(f"âœ… JSON íŒŒì‹± ì„±ê³µ! ë°˜í™˜ëœ ê²°ê³¼ ìˆ˜: {len(parsed_result)}ê°œ")
            
            # ê²°ê³¼ ìˆ˜ ê²€ì¦
            if len(parsed_result) != max_results:
                print(f"âš ï¸ ìš”ì²­í•œ {max_results}ê°œì™€ ë‹¤ë¥¸ {len(parsed_result)}ê°œì˜ ê²°ê³¼ê°€ ë°˜í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            return parsed_result
        except json.JSONDecodeError:
            print("âš ï¸ ì‘ë‹µì´ ìœ íš¨í•œ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
            return full_content
            
    except requests.exceptions.RequestException as e:
        print(f"âŒ ìš”ì²­ ì˜¤ë¥˜: {e}")
        return None
    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return None


def _handle_non_stream_response(url, payload, headers, max_results):
    """ë¹„ìŠ¤íŠ¸ë¦¼ ì‘ë‹µ ì²˜ë¦¬"""
    try:
        start_time = time.time()
        response = requests.post(url, json=payload, headers=headers)
        total_time = time.time() - start_time
        
        response.encoding = 'utf-8'
        
        if response.status_code == 200:
            data = response.json()
            content = data['choices'][0]['message']['content']
            
            print(f"ğŸ“„ ì‘ë‹µ ë‚´ìš©:\n{content}")
            
            print(f"\nğŸ“Š ë¹„ìŠ¤íŠ¸ë¦¼ í†µê³„:")
            print(f"ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ")
            print(f"ì‘ë‹µ ê¸¸ì´: {len(content)} ë¬¸ì")
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                parsed_result = json.loads(content)
                print(f"âœ… JSON íŒŒì‹± ì„±ê³µ! ë°˜í™˜ëœ ê²°ê³¼ ìˆ˜: {len(parsed_result)}ê°œ")
                
                # ê²°ê³¼ ìˆ˜ ê²€ì¦
                if len(parsed_result) != max_results:
                    print(f"âš ï¸ ìš”ì²­í•œ {max_results}ê°œì™€ ë‹¤ë¥¸ {len(parsed_result)}ê°œì˜ ê²°ê³¼ê°€ ë°˜í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
                return parsed_result
            except json.JSONDecodeError:
                print("âš ï¸ ì‘ë‹µì´ ìœ íš¨í•œ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
                return content
        else:
            print(f"âŒ API ì˜¤ë¥˜: {response.status_code}")
            print(f"ì˜¤ë¥˜ ë‚´ìš©: {response.text}")
            return None
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


def test_different_result_counts(query: str):
    """ë‹¤ì–‘í•œ ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ë¡œ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª ë‹¤ì–‘í•œ ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ í…ŒìŠ¤íŠ¸\n")
    print("=" * 80)
    
    result_counts = [3, 5, 8, 10]
    
    for count in result_counts:
        print(f"\nğŸ”¢ {count}ê°œ ê²°ê³¼ ìš”ì²­ í…ŒìŠ¤íŠ¸")
        print("-" * 50)
        
        result = websearch_with_stream(query, stream=True, max_results=count)
        
        if result and isinstance(result, list):
            print(f"\nğŸ“‹ ì‹¤ì œ ë°˜í™˜ëœ ê²°ê³¼ ìˆ˜: {len(result)}ê°œ")
            print(f"ğŸ“‹ ì²« ë²ˆì§¸ ê²°ê³¼ ì œëª©: {result[0].get('title', 'N/A')}")
            
            # ëª¨ë“  ê²°ê³¼ì˜ ì œëª©ë§Œ ê°„ë‹¨íˆ ì¶œë ¥
            for i, item in enumerate(result[:3], 1):  # ì²˜ìŒ 3ê°œë§Œ ì¶œë ¥
                print(f"  {i}. {item.get('title', 'N/A')}")
            if len(result) > 3:
                print(f"  ... ì™¸ {len(result) - 3}ê°œ ë”")
        else:
            print("âŒ ìœ íš¨í•œ ê²°ê³¼ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        
        print("\n" + "-" * 50)


def compare_stream_vs_non_stream(query: str, max_results: int = 5):
    """ìŠ¤íŠ¸ë¦¼ê³¼ ë¹„ìŠ¤íŠ¸ë¦¼ ë¹„êµ í…ŒìŠ¤íŠ¸"""
    # print("ğŸ†š ìŠ¤íŠ¸ë¦¼ vs ë¹„ìŠ¤íŠ¸ë¦¼ ì›¹ê²€ìƒ‰ ë¹„êµ\n")
    print("=" * 80)
    
    # # ë¹„ìŠ¤íŠ¸ë¦¼ í…ŒìŠ¤íŠ¸
    # print("\n1ï¸âƒ£ ë¹„ìŠ¤íŠ¸ë¦¼ ì›¹ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    # print("-" * 40)
    # non_stream_result = websearch_with_stream(query, stream=False, max_results=max_results)
    
    print("\n" + "=" * 80)
    
    # ìŠ¤íŠ¸ë¦¼ í…ŒìŠ¤íŠ¸
    print("\n2ï¸âƒ£ ìŠ¤íŠ¸ë¦¼ ì›¹ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print("-" * 40)
    
    stream_result = websearch_with_stream(query, stream=True, max_results=max_results)
    
    if stream_result and isinstance(stream_result, list) and len(stream_result) > 0:
        print(f"\nğŸ“‹ ìŠ¤íŠ¸ë¦¼ ê²°ê³¼ ({len(stream_result)}ê°œ):")
        print(f"ì œëª©: {stream_result[0].get('title', 'N/A')}")
        print(f"URL: {stream_result[0].get('url', 'N/A')}")
        print(f"ì ìˆ˜: {stream_result[0].get('score', 'N/A')}")
    else:
        print("âŒ ìŠ¤íŠ¸ë¦¼ì—ì„œ ìœ íš¨í•œ ê²°ê³¼ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    
    # ê²°ê³¼ ë¹„êµ
    print("\n" + "=" * 80)
    # print("\nğŸ” ê²°ê³¼ ë¶„ì„:")
    
    # if non_stream_result and stream_result:
    #     if isinstance(non_stream_result, list) and isinstance(stream_result, list):
    #         print(f"ë¹„ìŠ¤íŠ¸ë¦¼ ê²°ê³¼ ìˆ˜: {len(non_stream_result)}ê°œ")
    #         print(f"ìŠ¤íŠ¸ë¦¼ ê²°ê³¼ ìˆ˜: {len(stream_result)}ê°œ")
            
    #         if len(non_stream_result) > 0:
    #             print(f"\nğŸ“‹ ë¹„ìŠ¤íŠ¸ë¦¼ ì²« ë²ˆì§¸ ê²°ê³¼:")
    #             print(f"ì œëª©: {non_stream_result[0].get('title', 'N/A')}")
    #             print(f"URL: {non_stream_result[0].get('url', 'N/A')}")
            
    #         if len(stream_result) > 0:
    #             print(f"\nğŸ“‹ ìŠ¤íŠ¸ë¦¼ ì²« ë²ˆì§¸ ê²°ê³¼:")
    #             print(f"ì œëª©: {stream_result[0].get('title', 'N/A')}")
    #             print(f"URL: {stream_result[0].get('url', 'N/A')}")
    #     else:
    #         print("âš ï¸ ê²°ê³¼ê°€ ì˜ˆìƒëœ JSON ë°°ì—´ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
    # else:
    #     print("âŒ í•˜ë‚˜ ì´ìƒì˜ í…ŒìŠ¤íŠ¸ì—ì„œ ê²°ê³¼ë¥¼ ì–»ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")


def debug_stream_response(query: str):
    """ìŠ¤íŠ¸ë¦¼ ì‘ë‹µ ë””ë²„ê¹…"""
    print("ğŸ”§ ìŠ¤íŠ¸ë¦¼ ì‘ë‹µ ë””ë²„ê¹… ëª¨ë“œ\n")
    
    url = "https://api.perplexity.ai/chat/completions"
    
    payload = {
        "model": "sonar-pro",
        "messages": [
            {
                "content": "ê°„ë‹¨í•œ ì›¹ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”.",
                "role": "system"
            },
            {
                "role": "user",
                "content": query
            }
        ],
        "stream": True,
        "search_mode": "web"
    }
    
    headers = {
        "Authorization": f"Bearer {pplx_api_key}",
        "Content-Type": "application/json"
    }
    
    try:
        response = requests.post(url, json=payload, headers=headers, stream=True)
        
        print(f"ìƒíƒœ ì½”ë“œ: {response.status_code}")
        print(f"ì‘ë‹µ í—¤ë”: {dict(response.headers)}")
        print("-" * 50)
        
        chunk_count = 0
        for line in response.iter_lines():
            if line:
                chunk_count += 1
                line_str = line.decode('utf-8')
                print(f"[ì²­í¬ {chunk_count}] {line_str}")
                
                if chunk_count > 10:  # ì²˜ìŒ 10ê°œ ì²­í¬ë§Œ ì¶œë ¥
                    print("... (ë” ë§ì€ ì²­í¬ê°€ ìˆìŠµë‹ˆë‹¤)")
                    break
                    
    except Exception as e:
        print(f"ë””ë²„ê¹… ì¤‘ ì˜¤ë¥˜: {e}")


# ìƒˆë¡œìš´ í•¨ìˆ˜: ê²°ê³¼ ê°œìˆ˜ë³„ ì„±ëŠ¥ ë¹„êµ
def performance_test_by_result_count(query: str):
    """ê²°ê³¼ ê°œìˆ˜ë³„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("âš¡ ê²°ê³¼ ê°œìˆ˜ë³„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n")
    print("=" * 80)
    
    result_counts = [3, 5, 10]
    performance_data = []
    
    for count in result_counts:
        print(f"\nğŸ“Š {count}ê°œ ê²°ê³¼ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
        print("-" * 40)
        
        start_time = time.time()
        result = websearch_with_stream(query, stream=True, max_results=count)
        end_time = time.time()
        
        elapsed_time = end_time - start_time
        
        if result and isinstance(result, list):
            performance_data.append({
                'count': count,
                'time': elapsed_time,
                'actual_results': len(result)
            })
            print(f"â±ï¸ ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
            print(f"ğŸ“ˆ ì‹¤ì œ ê²°ê³¼ ìˆ˜: {len(result)}ê°œ")
        else:
            print("âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        
        print("-" * 40)
    
    # ì„±ëŠ¥ ìš”ì•½
    print(f"\nğŸ“ˆ ì„±ëŠ¥ ìš”ì•½:")
    print("-" * 30)
    for data in performance_data:
        print(f"{data['count']:2d}ê°œ ê²°ê³¼: {data['time']:5.2f}ì´ˆ (ì‹¤ì œ: {data['actual_results']}ê°œ)")


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    test_queries = [
        "perplexity webê²€ìƒ‰ ë„êµ¬ë¡œ ì“°ëŠ” ë°©ë²•",
        "Python ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ì²œ",
        "ìµœì‹  AI ë‰´ìŠ¤"
    ]
    
    print("ğŸš€ Perplexity API ì›¹ê²€ìƒ‰ ìŠ¤íŠ¸ë¦¼ í…ŒìŠ¤íŠ¸ ì‹œì‘\n")
    
    # 1. ê¸°ë³¸ ìŠ¤íŠ¸ë¦¼ í…ŒìŠ¤íŠ¸ (5ê°œ ê²°ê³¼)
    print("1ï¸âƒ£ ê¸°ë³¸ ìŠ¤íŠ¸ë¦¼ ì›¹ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (5ê°œ ê²°ê³¼)")
    result = websearch_with_stream(test_queries[0], stream=True, max_results=5)
    
    print("\n" + "=" * 80)
    
    # 2. ë‹¤ì–‘í•œ ê²°ê³¼ ê°œìˆ˜ í…ŒìŠ¤íŠ¸
    print("\n2ï¸âƒ£ ë‹¤ì–‘í•œ ê²°ê³¼ ê°œìˆ˜ í…ŒìŠ¤íŠ¸")
    test_different_result_counts(test_queries[1])
    
    print("\n" + "=" * 80)
    
    # 3. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    print("\n3ï¸âƒ£ ê²°ê³¼ ê°œìˆ˜ë³„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    performance_test_by_result_count(test_queries[2])
    
    print("\n" + "=" * 80)
    
    # 4. ê¸°ì¡´ ë¹„êµ í…ŒìŠ¤íŠ¸ (10ê°œ ê²°ê³¼ë¡œ)
    print("\n4ï¸âƒ£ ìŠ¤íŠ¸ë¦¼ í…ŒìŠ¤íŠ¸ (10ê°œ ê²°ê³¼)")
    compare_stream_vs_non_stream(test_queries[0], max_results=10)
    
    print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!") 