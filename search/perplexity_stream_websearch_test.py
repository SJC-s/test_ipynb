import requests
import json
import time
import os

# API í‚¤ ì„¤ì • (ì‹¤ì œ ì‚¬ìš© ì‹œ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
pplx_api_key = os.getenv("PPLX_API_KEY")

def websearch_with_stream(query: str, stream: bool = True):
    """
    Perplexity APIë¥¼ ì‚¬ìš©í•œ ì›¹ê²€ìƒ‰ - ìŠ¤íŠ¸ë¦¼ ëª¨ë“œ ì§€ì›
    
    Args:
        query: ê²€ìƒ‰í•  ì¿¼ë¦¬
        stream: ìŠ¤íŠ¸ë¦¼ ëª¨ë“œ ì‚¬ìš© ì—¬ë¶€
    """
    url = "https://api.perplexity.ai/chat/completions"
    
    payload = {
        "model": "sonar",  # sonar ëŒ€ì‹  sonar-pro ì‚¬ìš©
        "messages": [
            {
                "content": """
You are WebSearchBot, an AI assistant specialized in performing natural-language web searches and returning structured results.  

When a user asks a question in natural language:
1. Treat the entire user input as a search query.
2. Perform a real-time web search (e.g., via an API or search engine).
3. For each result, return a JSON object with these fields:
   - title: ë¬¸ì„œ ì œëª© (UTF-8 í…ìŠ¤íŠ¸, HTML íƒœê·¸ ì œê±°)
   - url: ë¬¸ì„œ URL
   - snippet: ê²€ìƒ‰ì–´ì™€ ì—°ê´€ëœ ìš”ì•½ë¬¸(ìµœì†Œ 200ì), ë¬¸ë§¥ ë’¤ "â€¦"ë¡œ íŠ¸ë ì¼€ì´íŠ¸
   - score: ê²€ìƒ‰ ê²°ê³¼ì˜ ìœ ì‚¬ë„ ì ìˆ˜(ì†Œìˆ˜ì  3ìë¦¬)
   - favicon: ë¬¸ì„œì˜ íŒŒë¹„ì½˜ URL
4. Return the overall answer as a JSON ë°°ì—´ë§Œ, ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ ì¶œë ¥í•˜ì„¸ìš”.
5. ì‘ë‹µì€ ë°˜ë“œì‹œ UTF-8 ì¸ì½”ë”©ìœ¼ë¡œ ì²˜ë¦¬í•˜ê³ , ëª¨ë“  ë¹„ASCII ë¬¸ìë¥¼ ê·¸ëŒ€ë¡œ ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤.
6. ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ë¹ˆ ë°°ì—´ `[]`ì„ ë°˜í™˜í•˜ì„¸ìš”.

Example response:
[
  {
    "title": "ì§ì¥ì¸ ì—…ë¬´ í•„ìˆ˜ íˆ´ ì°¸ê³ ìë£Œ ê²€ìƒ‰ì€ í¼í”Œë ‰ì‹œí‹° AIë¡œ í•´ê²°í•˜ëŠ” ë²•",
    "url": "https://example.com/article",
    "snippet": "â€¦ì§ì¥ì¸ë“¤ì´ ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” ì—…ë¬´ ë„êµ¬ì™€ ê·¸ ê¿€íŒì„ í¼í”Œë ‰ì‹œí‹° AI ê²€ìƒ‰ì„ í†µí•´ í•œëˆˆì— ì •ë¦¬í•˜ëŠ” ë°©ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤.â€¦",
    "score": 0.952,
    "favicon": "https://example.com/favicon.ico"
  }
]
                """,
                "role": "system"
            },
            {
                "role": "user",
                "content": query
            }
        ],
        "search_domain_filter": ["-youtube.com", "-youtube.be"],
        "search_mode": "web",
        "reasoning_effort": "medium",
        "temperature": 0.5,
        "top_p": 0.2,
        "stream": stream,  # ìŠ¤íŠ¸ë¦¼ ì„¤ì •
        "web_search_options": {"search_context_size": "medium"},
    }
    
    headers = {
        "Authorization": f"Bearer {pplx_api_key}",
        "Content-Type": "application/json"
    }
    
    print(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
    print(f"ğŸ“¡ ìŠ¤íŠ¸ë¦¼ ëª¨ë“œ: {'ON' if stream else 'OFF'}")
    print("-" * 60)
    
    if stream:
        return _handle_stream_response(url, payload, headers)
    else:
        return _handle_non_stream_response(url, payload, headers)


def _handle_stream_response(url, payload, headers):
    """ìŠ¤íŠ¸ë¦¼ ì‘ë‹µ ì²˜ë¦¬"""
    try:
        response = requests.post(url, json=payload, headers=headers, stream=True)
        
        if response.status_code != 200:
            print(f"âŒ API ì˜¤ë¥˜: {response.status_code}")
            print(f"ì˜¤ë¥˜ ë‚´ìš©: {response.text}")
            return None
        
        print("ğŸ“¡ ìŠ¤íŠ¸ë¦¼ ì‘ë‹µ ì‹œì‘...\n")
        
        full_content = ""
        chunk_count = 0
        start_time = time.time()
        first_chunk_time = None
        
        for line in response.iter_lines():
            if line:
                line_str = line.decode('utf-8')
                
                if line_str.startswith('data: '):
                    data_part = line_str[6:]
                    
                    if data_part.strip() == '[DONE]':
                        print("\n\nâœ… ìŠ¤íŠ¸ë¦¼ ì™„ë£Œ!")
                        break
                    
                    try:
                        chunk_data = json.loads(data_part)
                        chunk_count += 1
                        
                        if chunk_count == 1:
                            first_chunk_time = time.time() - start_time
                            print("ğŸš€ ì²« ë²ˆì§¸ ì²­í¬ ë„ì°©!\n")
                        
                        if 'choices' in chunk_data and len(chunk_data['choices']) > 0:
                            choice = chunk_data['choices'][0]
                            
                            if 'delta' in choice and 'content' in choice['delta']:
                                content = choice['delta']['content']
                                if content:
                                    print(content, end='', flush=True)
                                    full_content += content
                            
                            if choice.get('finish_reason'):
                                print(f"\n\nâœ… ì™„ë£Œ ì‚¬ìœ : {choice['finish_reason']}")
                                break
                        
                    except json.JSONDecodeError as e:
                        print(f"\nâŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
        
        total_time = time.time() - start_time
        
        print(f"\n\nğŸ“Š ìŠ¤íŠ¸ë¦¼ í†µê³„:")
        print(f"ì´ ì²­í¬ ìˆ˜: {chunk_count}")
        print(f"ì²« ì²­í¬ê¹Œì§€: {first_chunk_time:.2f}ì´ˆ" if first_chunk_time else "ì²« ì²­í¬ ì‹œê°„ ì¸¡ì • ì‹¤íŒ¨")
        print(f"ì „ì²´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ")
        print(f"ì‘ë‹µ ê¸¸ì´: {len(full_content)} ë¬¸ì")
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            parsed_result = json.loads(full_content)
            return parsed_result
        except json.JSONDecodeError:
            print("âš ï¸ ì‘ë‹µì´ ìœ íš¨í•œ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
            return full_content
            
    except requests.exceptions.RequestException as e:
        print(f"âŒ ìš”ì²­ ì˜¤ë¥˜: {e}")
        return None
    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return None


def _handle_non_stream_response(url, payload, headers):
    """ë¹„ìŠ¤íŠ¸ë¦¼ ì‘ë‹µ ì²˜ë¦¬"""
    try:
        start_time = time.time()
        response = requests.post(url, json=payload, headers=headers)
        total_time = time.time() - start_time
        
        response.encoding = 'utf-8'
        
        if response.status_code == 200:
            data = response.json()
            content = data['choices'][0]['message']['content']
            
            print(f"ğŸ“„ ì‘ë‹µ ë‚´ìš©:\n{content}")
            
            print(f"\nğŸ“Š ë¹„ìŠ¤íŠ¸ë¦¼ í†µê³„:")
            print(f"ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ")
            print(f"ì‘ë‹µ ê¸¸ì´: {len(content)} ë¬¸ì")
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                parsed_result = json.loads(content)
                return parsed_result
            except json.JSONDecodeError:
                print("âš ï¸ ì‘ë‹µì´ ìœ íš¨í•œ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
                return content
        else:
            print(f"âŒ API ì˜¤ë¥˜: {response.status_code}")
            print(f"ì˜¤ë¥˜ ë‚´ìš©: {response.text}")
            return None
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


def compare_stream_vs_non_stream(query: str):
    """ìŠ¤íŠ¸ë¦¼ê³¼ ë¹„ìŠ¤íŠ¸ë¦¼ ë¹„êµ í…ŒìŠ¤íŠ¸"""
    # print("ğŸ†š ìŠ¤íŠ¸ë¦¼ vs ë¹„ìŠ¤íŠ¸ë¦¼ ì›¹ê²€ìƒ‰ ë¹„êµ\n")
    print("=" * 80)
    
    # # ë¹„ìŠ¤íŠ¸ë¦¼ í…ŒìŠ¤íŠ¸
    # print("\n1ï¸âƒ£ ë¹„ìŠ¤íŠ¸ë¦¼ ì›¹ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    # print("-" * 40)
    # non_stream_result = websearch_with_stream(query, stream=False)
    
    print("\n" + "=" * 80)
    
    # ìŠ¤íŠ¸ë¦¼ í…ŒìŠ¤íŠ¸
    print("\n2ï¸âƒ£ ìŠ¤íŠ¸ë¦¼ ì›¹ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print("-" * 40)
    
    stream_result = websearch_with_stream(query, stream=True)
    print(f"\nğŸ“‹ ìŠ¤íŠ¸ë¦¼ ì²« ë²ˆì§¸ ê²°ê³¼:")
    print(f"ì œëª©: {stream_result[0].get('title', 'N/A')}")
    print(f"URL: {stream_result[0].get('url', 'N/A')}")
    
    # ê²°ê³¼ ë¹„êµ
    print("\n" + "=" * 80)
    # print("\nğŸ” ê²°ê³¼ ë¶„ì„:")
    
    # if non_stream_result and stream_result:
    #     if isinstance(non_stream_result, list) and isinstance(stream_result, list):
    #         print(f"ë¹„ìŠ¤íŠ¸ë¦¼ ê²°ê³¼ ìˆ˜: {len(non_stream_result)}ê°œ")
    #         print(f"ìŠ¤íŠ¸ë¦¼ ê²°ê³¼ ìˆ˜: {len(stream_result)}ê°œ")
            
    #         if len(non_stream_result) > 0:
    #             print(f"\nğŸ“‹ ë¹„ìŠ¤íŠ¸ë¦¼ ì²« ë²ˆì§¸ ê²°ê³¼:")
    #             print(f"ì œëª©: {non_stream_result[0].get('title', 'N/A')}")
    #             print(f"URL: {non_stream_result[0].get('url', 'N/A')}")
            
    #         if len(stream_result) > 0:
    #             print(f"\nğŸ“‹ ìŠ¤íŠ¸ë¦¼ ì²« ë²ˆì§¸ ê²°ê³¼:")
    #             print(f"ì œëª©: {stream_result[0].get('title', 'N/A')}")
    #             print(f"URL: {stream_result[0].get('url', 'N/A')}")
    #     else:
    #         print("âš ï¸ ê²°ê³¼ê°€ ì˜ˆìƒëœ JSON ë°°ì—´ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
    # else:
    #     print("âŒ í•˜ë‚˜ ì´ìƒì˜ í…ŒìŠ¤íŠ¸ì—ì„œ ê²°ê³¼ë¥¼ ì–»ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")


def debug_stream_response(query: str):
    """ìŠ¤íŠ¸ë¦¼ ì‘ë‹µ ë””ë²„ê¹…"""
    print("ğŸ”§ ìŠ¤íŠ¸ë¦¼ ì‘ë‹µ ë””ë²„ê¹… ëª¨ë“œ\n")
    
    url = "https://api.perplexity.ai/chat/completions"
    
    payload = {
        "model": "sonar-pro",
        "messages": [
            {
                "content": "ê°„ë‹¨í•œ ì›¹ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”.",
                "role": "system"
            },
            {
                "role": "user",
                "content": query
            }
        ],
        "stream": True,
        "search_mode": "web"
    }
    
    headers = {
        "Authorization": f"Bearer {pplx_api_key}",
        "Content-Type": "application/json"
    }
    
    try:
        response = requests.post(url, json=payload, headers=headers, stream=True)
        
        print(f"ìƒíƒœ ì½”ë“œ: {response.status_code}")
        print(f"ì‘ë‹µ í—¤ë”: {dict(response.headers)}")
        print("-" * 50)
        
        chunk_count = 0
        for line in response.iter_lines():
            if line:
                chunk_count += 1
                line_str = line.decode('utf-8')
                print(f"[ì²­í¬ {chunk_count}] {line_str}")
                
                if chunk_count > 10:  # ì²˜ìŒ 10ê°œ ì²­í¬ë§Œ ì¶œë ¥
                    print("... (ë” ë§ì€ ì²­í¬ê°€ ìˆìŠµë‹ˆë‹¤)")
                    break
                    
    except Exception as e:
        print(f"ë””ë²„ê¹… ì¤‘ ì˜¤ë¥˜: {e}")


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    test_queries = [
        "perplexity webê²€ìƒ‰ ë„êµ¬ë¡œ ì“°ëŠ” ë°©ë²•",
        "Python ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ì²œ",
        "ìµœì‹  AI ë‰´ìŠ¤"
    ]
    
    print("ğŸš€ Perplexity API ì›¹ê²€ìƒ‰ ìŠ¤íŠ¸ë¦¼ í…ŒìŠ¤íŠ¸ ì‹œì‘\n")
    
    # 1. ê¸°ë³¸ ìŠ¤íŠ¸ë¦¼ í…ŒìŠ¤íŠ¸
    print("1ï¸âƒ£ ê¸°ë³¸ ìŠ¤íŠ¸ë¦¼ ì›¹ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    result = websearch_with_stream(test_queries[0], stream=True)
    
    print("\n" + "=" * 80)
    
    # 2. ë¹„êµ í…ŒìŠ¤íŠ¸
    print("\n2ï¸âƒ£ ìŠ¤íŠ¸ë¦¼ vs ë¹„ìŠ¤íŠ¸ë¦¼ ë¹„êµ")
    compare_stream_vs_non_stream(test_queries[1])
    
    print("\n" + "=" * 80)
    
    # 3. ë””ë²„ê¹… í…ŒìŠ¤íŠ¸
    print("\n3ï¸âƒ£ ìŠ¤íŠ¸ë¦¼ ì‘ë‹µ ë””ë²„ê¹…")
    debug_stream_response(test_queries[2])
    
    print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!") 